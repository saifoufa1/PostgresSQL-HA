### Target Topology (pg_auto_failover Based)

| Component         | Container name     | Role / Notes                                                            | Ports (container) | Host map                  | Persistent volume            |
|-------------------|--------------------|---------------------------------------------------------------------------|-------------------|---------------------------|------------------------------|
| Monitor           | pgaf-monitor       | pg_auto_failover monitor supervising formation and node health.          | 5431              | 5431 -> 5431              | monitor_data                 |
| Primary candidate | postgres-primary   | Managed by pg_autoctl keeper; bootstrap applies schema and seed data.    | 5432, 6010        | 5432 -> 5432, 6010 -> 6010 | postgres-primary             |
| Replica #1        | postgres-replica1  | Keeper-managed standby, preferred failover target (candidate priority). | 5432, 6011        | 5433 -> 5432, 6011 -> 6011 | postgres-replica1            |
| Replica #2        | postgres-replica2  | Second keeper-managed standby for redundancy/tests.                      | 5432, 6012        | 5434 -> 5432, 6012 -> 6012 | postgres-replica2            |
| Postgres exporter | postgres-exporter  | Scrapes whichever node is writable (`target_session_attrs=read-write`).  | 9187              | 9187                       | -                            |
| Prometheus        | prometheus         | Collects metrics from exporter and serves `/metrics`.                     | 9090              | 9090                       | prometheus_data (optional)   |

**Networking**
- Single custom Docker network `postgres-cluster` with subnet `172.28.0.0/24` (static IPs retained).
- Node hostnames for pg_auto_failover are `postgres-primary`, `postgres-replica1`, `postgres-replica2` so lookups remain backward compatible.
- Keeper coordination ports `6010-6012` exposed for debugging; clients connect via 5432/5433/5434 as before.

**Process Layout**
- Container entrypoints run pg_autoctl directly (official Postgres entrypoint is bypassed).
- Monitor volume contains pg_auto_failover metadata; each node volume holds Postgres data under `/var/lib/postgresql/pgdata`.
- `primary-bootstrap.sh` waits for keeper promotion, applies schema (`sql/01-schema.sql`) and data (`sql/02-test-data.sql`) once.

**Volumes**
- `monitor_data` -> `/var/lib/postgresql/monitor`
- `postgres-primary`, `postgres-replica1`, `postgres-replica2` -> `/var/lib/postgresql` (keepers manage `pgdata` subdir)
- Optional `prometheus_data` volume can be added for long lived metrics storage.

**Environment and Credentials**
- Monitor auth is set to `trust` inside the lab network; keepers authenticate with the autogenerated `autoctl_node` role.
- Application superuser stays `postgres/postgres_password`; schema/bootstrap toggled via `LOAD_SCHEMA` / `LOAD_TEST_DATA` in `.env.*`.
- `target_session_attrs=read-write` in exporter DSN automatically follows the elected primary.
